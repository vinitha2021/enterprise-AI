{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from string import punctuation\n",
    "import tensorflow as tf \n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading trained model and basic steps to set trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Amazon Product Reviews1.csv')\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset.drop( columns = {'HelpfulnessNumerator','HelpfulnessDenominator','Time'})\n",
    "dataset['Sentiment'] = 0\n",
    "dataset['Sentiment'][dataset.Score >= 3] = 1\n",
    "dataset['Text'] = dataset['Text'].str.lower()\n",
    "dataset['Text'] = dataset['Text'].str.replace('[{}]'.format(punctuation), '')\n",
    "text_list = dataset.Text.to_list()\n",
    "tokenizer = Tokenizer(num_words=len(text_list))\n",
    "tokenizer.fit_on_texts(text_list)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "encoded_docs = tokenizer.texts_to_sequences(text_list)\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resulting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    model = tf.keras.models.load_model('my_model.h5')\n",
    "    text = TextArea.get('end')\n",
    "    tw = tokenizer.texts_to_sequences([text])\n",
    "    tw = pad_sequences(tw,maxlen=400)\n",
    "    prediction = int(model.predict(tw).round().item())\n",
    "    print(\"Sentiment :- Negative -> 0 & Postive -> 1\")\n",
    "    print(\"predictied result -> {}\".format(prediction))\n",
    "    if prediction == 1:\n",
    "        text1 = tk.Label(frame,text=\"Review is positive !!\",font=(\"Helvetica\", 16))\n",
    "        text1.place(x=150, y=260)\n",
    "    else:\n",
    "        text1 = tk.Label(frame,text=\"Review is negative !!\",font=(\"Helvetica\", 16))\n",
    "        text1.place(x=150, y=260)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tkinter window setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.geometry(\"640x480\")\n",
    "root.resizable(0, 0)\n",
    "root.title(\"Enterprise AI Analysis\")\n",
    "frame=tk.Frame(root, width=500, height=290)\n",
    "frame.pack()\n",
    "text1 = tk.Label(text=\"Review for sentiment analysis:\",font=(\"Helvetica\", 16))\n",
    "text1.place(x=10, y=40)\n",
    "TextArea = tk.Text()\n",
    "TextArea.pack(expand='YES', fill='both')\n",
    "TextArea.place(x=10, y=90, height=100, width=600)\n",
    "button1 = tk.Button(frame, text=\"Result\", command = model)\n",
    "button1.place(x=180, y=210, height=30, width=100)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
